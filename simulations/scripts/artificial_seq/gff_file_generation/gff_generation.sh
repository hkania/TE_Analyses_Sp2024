#!/usr/bin/env bash

#SBATCH --output=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/scripts/gff_gen_outputs/myoluc_test_full.out
#SBATCH --error=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/scripts/gff_gen_outputs/myoluc_test_full.err
#SBATCH --partition=yoderlab
#SBATCH --account=yoderlab
#SBATCH --mail-type=ALL
#SBATCH --mail-user=hpk4@duke.edu
#SBATCH --mem=10G

#This script goes through the log file generated by Garlic v.1.4 updated to reflect zero-based counts that mirrors
#Garlic v.1.5. It parses based on the start and end line of each artificial sequenced generated. To update this script,
#replace the variables in the general definitions section at the top of the page.
#The END number should reflect the total number of sequences generated by GARLIC in one run, minus 1.
#You will need to also change your file paths, as of 08/29/2024. The idea is to update the script to have variables
#specified at the top, as well as environments provided in .yaml files so the user can provide necessary
#environments via miniconda and variables reflecting their computational organization (HPC cluster here),
#then plug and chug the following script to generate GFF files from the output error/log file of a Garlic
#createFakeSequence.pl run.

#### GENERAL DEFINITIONS NECESSARY FOR THE SCRIPT ####

END=2 #total number of sequences generated with Garlic run, minus 1
model=myoluc #model used for fake fastas
export model #sets model variable for later on awk script
out_header=myoluc2_100Mb_fin #header of the output log file, based on DCC organization
log_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/${out_header}.err #log file path
LAST=$((${END}+1)) #total number of sequences generated
echo "Last = ${LAST}"

##### SECTION 1: FOR SEQUENCES UP TO THE SECOND TO LAST ONE GENERATED BY GARLIC #####

###########################################################################################################################
## 		PART A: SPLITTING LOG FILES WHEN MORE THAN ONE SEQUENCE IS GENERATED WITH GARLIC AT A TIME		 ##
## 		In this section, the log file produced by Garlic is parsed into files for each sequence generated.	 ##
###########################################################################################################################

echo "###Starting Section 1, Part A, Splitting log files"
echo "Model ${model}, first artifical sequence: ${END}, last artificial sequence: ${LAST}"
echo "#############################"
date
echo "#############################"

for num in $(seq 1 ${END}); do #for numbers from 1 to the second to last sequence, do ***EDIT BEFORE RUNNING ON WHOLE SERIES to be 1 ${END}

	next_num=$((${num}+1)) #record the next number in the sequence
	echo "##current artificial sequence num: ${num} , next number: ${next_num}" #echo the current sequence and next
	line_with_create=$(grep -n "creating new sequence ( length 100000000 )" ${log_file} | head -n ${num} | tail -n 1 | cut -d : -f 1) #define the line number where the num sequence starts to be generated
	line_of_build=$(grep -n "Base sequence generated (100000000 bases)" ${log_file} | head -n ${num} | tail -n 1 | cut -d : -f 1) #define the line number where the num sequence is finished
	next_seq_start=$(grep -n "creating new sequence ( length 100000000 )" ${log_file} | head -n ${next_num} | tail -n 1 | cut -d : -f 1) #define the line number where the next num sequence starts to be generated
	echo "create line: ${line_with_create}" #echo the creation line number
	echo "build line: ${line_of_build}" #echo the end of build line number
	echo "stop line: ${next_seq_start}" #echo the next creation line number
	diff_num_1=$((${next_seq_start}-${line_with_create}+1)) #define the range that includes the entirety of the num sequence generation log
	diff_num_2=$((${next_seq_start}-${line_with_create})) #define the difference between the next creation line number and the first creation line number
	echo "head check below:" #echo to make note of the head of the below output which records the entirety of the num sequence log
	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} | head -n 1
	echo "tail check below:" #echo to make note of the tail of the output
	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} | tail -n 1
	output_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_log_${num}.txt #define the output file based on the model and artificial sequence number
	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} > ${output_file} #formally produce the output file that includes the entirety of the log file for the generation of the num artificial sequence

	number_inserts=$(grep "Inserting:" ${output_file} | wc -l) #define the number of inserts in the final sequence based on those specified to be inserted in the log file
	echo "Number of inserts in artificial seq ${num} : ${number_inserts}" #echo this number
	output_file_2=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_list_${num}.txt #define the output for the inserts of the num artificial sequence based on the log file
	grep "Inserting:" ${output_file} > ${output_file_2} #formally generate the insert output file, which should include the location and name of each insert
	number_inserts_final=$(cat ${output_file_2} | wc -l) #define the number of inserts
	echo "Number of finalized inserts in artificial seq ${num} : ${number_inserts_final}" #check to make sure the number matches that of the one above using echo

###################################################################################################################################################
## 		PART B: DEFINING TEs 							   	 						 ##
## 		In this secion the nested and single inserts for each artifical sequence are defined and printed to separate output files.	 ##
###################################################################################################################################################

	echo "###Starting Section 1, Part B, Defining TEs for seq num ${model}_artificial_sequence_${num}"
	echo "#############################"
	date
	echo "#############################"

	output_file_3=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_nest_${num}.txt #define the output file which only includes the nested inserts 
	awk '$5 ~ /,/ {print $0}' ${output_file_2} >> ${output_file_3} #use awk to grab nested inserts, which have a comma in their 5th field (commas in the actual repeat content defining nested inserts)
	output_file_4=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_sing_${num}.txt #define the output file which only includes non-nested, single inserts
	awk '$5 ~ /,/ { next } { print $0 }' ${output_file_2} >> ${output_file_4} #use awk to skip lines which have commas and only print lines without commas in the fifth field
	echo "Head of nested TE file"
	head ${output_file_3} -n 1 #check first output is actually nested
	echo "Head of single TE file"
	head ${output_file_4} -n 2 #check second output is not nested
	num_nest_inserts=$(cat ${output_file_3} | wc -l) #count number of nested inserts
	num_sing_inserts=$(cat ${output_file_4} | wc -l) #count number of single inserts
	total_num_inserts_defined=$((${num_nest_insersts}+${num_sing_inserts}))
	echo "total inserts: ${number_inserts_final}, defined inserts: ${total_num_inserts_defined}, singular inserts: ${num_sing_inserts}, nested inserts: ${num_nest_inserts}" #check to make sure totals are adding up

###################################################################################################################################################
## 		PART C: NESTED TE CONSENSUS SEQUENCES 											 	 ##
## 		In this section the nested TE sequences and resulting consensus sequences are printed to a final file for downstream analyses.	 ##
###################################################################################################################################################

	echo "###Starting Section 1, Part C, Nested TE consensus seqs for seq num ${model}_artificial_sequence_${num}"
	echo "#############################"
	date
	echo "#############################"

	search_term=$(cat ${output_file_3} | cut -f 2) #define the search term based on the second field of the nested inserts file
	search_count=$(cat ${output_file_3} | cut -f 2 | wc -l) #count how many nested inserts
	echo "Count starting file: ${search_count}" #echo the number of nested inserts
	search_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/fake_fastas/${model}/${model}.inserts.split/${model}_${num}_inserts.txt #define the search file (the file containing all of the inserts and their sequences, generated by garlic itself and not the log file)
	nest_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_int_nest_${num}_file #define an intermediate nested sequence file
	echo "Nested file: ${nest_file}"
        for stop in ${search_term[@]}; do #for every search term, grab the search term in the search file and print the result to the intermediate nested file
               grep -w "${stop}" ${search_file} >> ${nest_file}
        done

        amount=$(cat ${nest_file} | wc -l) #count the amount of inserts in the nested file
        echo "Nested file count: ${amount}"
        final_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/final_${model}_${num}_nested.txt #define the final nested insert file
        echo "Final file: ${final_file}"
        awk '$4 ~ /,/ {print $0}' ${nest_file} | sort --unique >> ${final_file} #only keep terms that are nested TE (contain commas), and only keep unique returns
        amount_2=$(cat ${final_file} | wc -l) #count the number of final nested TEs in the nest file
        echo "Final file count: ${amount_2}, should match search count: ${search_count}" #
        echo "Removing intermediate files: ${nest_file}"
        rm ${nest_file}

done

echo "###Finished Section 1, splitting all files minus the last"
echo "#############################"
date
echo "#############################"

########## SECTION 2: FOR THE LAST SEQUENCE GENERATED BY GARLIC IN ONE RUN #####
###This is a repeat of the above but for the final sequence, as the way the other sequences are defined in the log file is by the start of a
###new artificial sequence generation. The last sequence does not have another sequence to define it, so the definitions change slightly.

###########################################################################################################################
## 		PART A: SPLITTING LOG FILES WHEN MORE THAN ONE SEQUENCE IS GENERATED WITH GARLIC AT A TIME 		 ##
## 		In this section, the log file produced by Garlic is parsed into files for each sequence generated.	 ##
###########################################################################################################################

#echo "###Starting Section 2, Part A, Splitting last log file"
#echo "#############################"
#date
#echo "#############################"

#for num in $(seq ${LAST} ${LAST}); do #for the last query sequence in the inserts file, the only thing that really changes is the definition of the end line, which will be the last line of the input file instead of the next artificial sequence since there isn't one.

#	echo "current artificial sequence num: ${model}_artificial_sequence_${num}"
#	line_with_create=$(grep -n "creating new sequence ( length 100000000 )" ${log_file} | head -n ${num} | tail -n 1 | cut -d : -f 1)
#	line_of_build=$(grep -n "Base sequence generated (100000000 bases)" ${log_file} | head -n ${num} | tail -n 1 | cut -d : -f 1)
#	next_seq_start=$(cat ${log_file} | wc -l) #define the next sequence start number, which should be the last line of the log file
#	echo "create line: ${line_with_create}"
#	echo "build line: ${line_of_build}"
#	echo "stop line: ${next_seq_start}"
#	diff_num_1=$((${next_seq_start}-${line_with_create}+1))
#	diff_num_2=$((${next_seq_start}-${line_with_create}))
#	echo "head check below:"
#	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} | head -n 1
#	echo "tail check below:"
#	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} | tail -n 1
#	output_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_log_${num}.txt #define the output file based on the model and artificial sequence number
#	cat ${log_file} | head -n ${next_seq_start} | tail -n ${diff_num_1} | head -n ${diff_num_2} > ${output_file}

#	number_inserts=$(grep "Inserting:" ${output_file} | wc -l)
#	echo "Number of inserts in artificial seq ${num} : ${number_inserts}"
#	output_file_2=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_list_${num}.txt #define the output for the inserts of the num artificial sequence based on the log file
#	grep "Inserting:" ${output_file} > ${output_file_2}
#	number_inserts_final=$(cat ${output_file_2} | wc -l)
#	echo "Number of finalized inserts in artificial seq ${model}_artificial_sequence_${num} : ${number_inserts_final}"

###################################################################################################################################################
## 		PART B: DEFINING TEs 														 ##
## 		In this secion the nested and single inserts for each artifical sequence are defined and printed to separate output files.	 ##
###################################################################################################################################################

#	echo "###Starting Section 2, Part B, Defining TEs for seq num ${model}_artificial_sequence_${num}"
#	echo "#############################"
#	date
#	echo "#############################"

#	output_file_3=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_nest_${num}.txt #define the output file which only includes the nested inserts 
#	awk '$5 ~ /,/ {print $0}' ${output_file_2} >> ${output_file_3} #use awk to grab nested inserts, which have a comma in their 5th field (commas in the actual repeat content defining nested inserts)
#	output_file_4=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_inserts_sing_${num}.txt #define the output file which only includes non-nested, single inserts
#	awk '$5 ~ /,/ { next } { print $0 }' ${output_file_2} >> ${output_file_4} #use awk to skip lines which have commas and only print lines without commas in the fifth field
#	echo "Head of nested TE file"
#	head ${output_file_3} -n 1 #check first output is actually nested
#	echo "Head of single TE file"
#	head ${output_file_4} -n 2 #check second output is not nested
#	num_nest_inserts=$(cat ${output_file_3} | wc -l) #count number of nested inserts
#	num_sing_inserts=$(cat ${output_file_4} | wc -l) #count number of single inserts
#	total_num_inserts_defined=$((${num_nest_insersts}+${num_sing_inserts}))
#	echo "total inserts: ${number_inserts_final}, defined inserts: ${total_num_inserts_defined}, singular inserts: ${num_sing_inserts}, nested inserts: ${num_nest_inserts}" #check to make sure totals are adding up

###########################################################################################################################################
## 		PART C: NESTED TE CONSENSUS SEQUENCES 																						 	 ##
## 		In this section the nested TE sequences and resulting consensus sequences are printed to a final file for downstream analyses.	 ##
###########################################################################################################################################

#	echo "###Starting Section 2, Part C, Nested TE consensus seqs for seq num ${model}_artificial_sequence_${num}"
#	echo "#############################"
#	date
#	echo "#############################"

#	search_term=$(cat ${output_file_3} | cut -f 2) #define the search term based on the second field of the nested inserts file
#	search_count=$(cat ${output_file_3} | cut -f 2 | wc -l) #count how many nested inserts
#	echo "Count starting file: ${search_count}" #echo the number of nested inserts
#	search_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/fake_fastas/${model}/${model}.inserts.split/${model}_${num}_inserts.txt #define the search file (the file containing all of the inserts and their sequences, generated by garlic itself and not the log file)
#	nest_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}_int_nest_${num}_file #define an intermediate nested sequence file
#	echo "Nested file: ${nest_file}"
#	for stop in ${search_term[@]}; do #for every search term, grab the search term in the search file and print the result to the intermediate nested file
#               grep -w "${stop}" ${search_file} >> ${nest_file}
#        done

#        amount=$(cat ${nest_file} | wc -l) #count the amount of inserts in the nested file
#        echo "Nested file count: ${amount}"
#        final_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/final_${model}_${num}_nested.txt #define the final nested insert file
#        echo "Final file: ${final_file}"
#        awk '$4 ~ /,/ {print $0}' ${nest_file} | sort --unique >> ${final_file} #only keep terms that are nested TE (contain commas), and only keep unique returns
#        amount_2=$(cat ${final_file} | wc -l) #count the number of final nested TEs in the nest file
#        echo "Final file count: ${amount_2}, should match search count: ${search_count}" #
#        echo "Removing intermediate files: ${nest_file}"
#        rm ${nest_file}

#done

#echo "###Finished Section 2, splitting last log file and defining TEs"
#echo "#############################"
#date
#echo "#############################"

##### SECTION 3 FOR ALL SEQUENCES #####

##############################################
## 		PART A: CLEAN UP FOLDERS    ##
##############################################

echo "###Starting Section 3, Part A, Cleaning up folders after initial TEs are defined for all artifical sequences specified"
echo "Model ${model}, first artifical sequence: ${END}, last artificial sequence: ${LAST}"
echo "#############################"
date
echo "#############################"

echo "Organizing intermediate files"
#make the directories and define variables
mkdir -p /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/logs
log_dir=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/logs
mkdir -p /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/nested
nest_dir=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/nested
mkdir -p /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/single
sing_dir=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/single
mkdir -p /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/inserts
list_dir=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/inserts
mkdir -p /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/final
final_dir=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/final

##move files to corresponding directories
mv /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}*log* ${log_dir} #move final split log files to the log directory
mv /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}*sing* ${sing_dir} #move final single TE files to the single directory
mv /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}*nest_* ${nest_dir} #remove if works well
mv /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}*list* ${list_dir} #move the combined insert files to the list directory
mv /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/final*${model}* ${final_dir} #move final nested files to the nest directory

echo "Gzipping inserts file directory as duplicated data" #this can be gzipped if you like to save space, as it includes information contained in the single TE and nested TE files
gzip_dir=rep.inserts.tar.gz
cd /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}
tar -zcvf ${gzip_dir} ${list_dir} ${nest_dir}
rm -r ${list_dir}

echo "Log files can be found in ${log_dir}"
echo "Nested files can be found in ${final_dir}"
echo "Single files can be found in ${sing_dir}"
echo "Intermdiate, repeated information zipped files can be found in ${gzip_dir}"
date


##################################################################################################################################
## 		PART B: SINGLE TE CONSENSUS SEQUENCES 										##
## 		In this secion the single TE file is parsed and stop positions are defined for the final GFF3 file.	 	##
##################################################################################################################################

echo "###Starting Section 3, Part B, Single TE GFF Generation"
echo "Model ${model}, first artifical sequence: ${END}, last artificial sequence: ${LAST}"
echo "#############################"
date
echo "#############################"

mkdir -p /datacommons/yoderlab/users/hkania/garlic_gffs/${model} #make a directory for gff files

for num in $(seq 1 ${END}); do
    echo "Sequence number: ${model}_artificial_sequence_${num}" #define the sequence number

    sing_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/single/${model}_inserts_sing_${num}.txt #define the file with single TE inserts
    echo "Single TE File: ${sing_file}"
    start_pos=$(cat ${sing_file} | cut -f 1 | sed 's/.* //') #create file with the starting positions

    echo "Starting GFF generation from single repeats"
    date
	for value in ${start_pos[@]}; do #for every starting position
                start_ini=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 1 | sed 's/.* //') #define the start position
                start=$((${start_ini}+1)) #add one to reflect zero-based Garlic
                stop=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 2) #define the stop position
                strand=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 4 | cut -d: -f 3) #define the strand, positive or negative
                repeat=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 4 | cut -d: -f 1,2) #define the repeat type
                extra1=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 4 | cut -d: -f 4-8) #define extra information about the TE (specifics as outlined in Garlic script)
                extra2=$(grep -w "Inserting: ${value}" ${sing_file} | cut -f 5 | cut -d ' ' -f 1-16 | tr -d ' ') #define extra information about the TE (%divergence)
                echo -e "${model}_artificial_sequence_${num}\tGARLIC\t${repeat}\t${start}\t${stop}\t100\t${strand}\t.\t${extra1};${extra2}" \
                        >> /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}.gff #build the gff file
    done
	cat /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}.gff | sort --unique > /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_un.gff

	echo "Finished single TE GFF generation for sequence number ${model}_artificial_sequence_${num}"

    echo "###Performing length comparison"
    length=$(cat /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}.gff | wc -l)
    match=$(cat ${sing_file} | wc -l)
    echo "File can be found at /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}.gff"
    echo "GFF repeat count: ${length}"
    echo "###should match original single repeat number: ${match}"
done

echo "Finished Single TE GFF Generation for all sequences specified"
echo "Model ${model}, first artifical sequence: ${END}, last artificial sequence: ${LAST}"
date

###############################################################################################################################################################
## 		PART C: NESTED TE CONSENSUS SEQUENCES 																						 						 ##
## 		In this secion the nested file is parsed by TEs and sent through NCBI Blast+ to define nested TE start and stop positions for the final GFF3 file.	 ##
###############################################################################################################################################################

echo "###Starting Section 3, Part C, Nested TE Consensus Blast"
echo "#############################"
date
echo "#############################"

for num in $(seq 1 ${END}); do
	echo "Starting blast for Sequence ${num}"
	date
	export num #exports num variable for later awk script
	final_nest_file=/datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/split_art_logs/${model}/final/final_${model}_${num}_nested.txt #defines the final nested file
	search_term2=$(cat ${final_nest_file} | cut -f 2) #builds the search term file based on the stop position of each nested TE
	mkdir -p /cwork/hpk4/insert_splitting/${model}/${num} #make directory to house intermediate ncbi files
	dir=/cwork/hpk4/insert_splitting/${model}/${num} #define the directory path
	for stop in ${search_term2[@]}; do #for every stop position of a nested TE
		export stop
		awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | sed 's/\[/\n/g' | sed 's/,/\n/g' | head -n 1 >> ${dir}/insert_${stop}_refx.fasta #grep the stop position and pull out the initial insert name
		awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | sed 's/\[/\n/g' | sed 's/,/\n/g' | tail -n +2 | head -n -1 | sed '1~2s/^/>/' | sed '2~2s/.$//' >> ${dir}/insert_${stop}_query.fasta #grep the stop position and pull out the inserted insert names and corresponding sequence, then put into fasta format
		awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | sed 's/\[/\n/g' | sed 's/,/\n/g' | tail -n 1 | sed 's/.$//' >> ${dir}/insert_${stop}_refx.fasta #add the reference sequence to the reference file
		sed '1~2s/^/>/' ${dir}/insert_${stop}_refx.fasta >> ${dir}/insert_${stop}_refx.fasta #add the fasta file indicator
	    	cat ${dir}/insert_${stop}_refx.fasta | tail -n 2 > ${dir}/insert_${stop}_ref.fasta #make final reference file for ncbi blast
		rm /cwork/hpk4/insert_splitting/${model}/${num}/insert_${stop}_refx.fasta #remove intermediate file
		cd ${dir}
		source ~/miniconda3/etc/profile.d/conda.sh #load miniconda env, specified in .yaml file in GitHub
	        conda activate ncbi_blast #load miniconda env (specified in .yaml file in GitHub)
        	makeblastdb -in ${dir}/insert_${stop}_ref.fasta -dbtype nucl -out ${dir}/db_${stop}
	        blastn -query ${dir}/insert_${stop}_query.fasta -db db_${stop} -out ${dir}/${stop}.align -outfmt 6 -perc_identity 100 -qcov_hsp_perc 100 -word_size 10 #generate alignment file with start and stop positions
        	conda deactivate
		rm ${dir}/insert_${stop}_query.fasta ${dir}/insert_${stop}_ref.fasta ${dir}/db_${stop}* #remove temporary files

		align_file=${dir}/${stop}.align #define the align file
	        start=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 1) #define the starting position for the entire nested element
		real_start=$((${start}))
	        end=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 2) #define the end position for the entire nested element

		cat ${align_file} | sort -nrk4 | awk -f /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/scripts/sequence_start_stop.awk | awk '!seen[$2]++' > ${dir}/${stop}.out #sort the alignment file from largest element to shortest element, keep only 100% matches, remove duplicated matches or overlap from similar elements, ie. keep the longest
        	insert_positions_start=$(cat ${dir}/${stop}.out | cut -f 2) #define the smaller insert starting positions relative to the whole nested element not the whole artificial sequence
	        insert_positions_stop=$(cat ${dir}/${stop}.out | cut -f 3) #define the smaller insert ending positions relative to the whole nested element not the whole artificial sequence
            	for insert in ${insert_positions_start[@]}; do #for each starting position
                	new_start=$((${insert}+${real_start})) #define the starting position based on the position of the whole nested element within the artificial sequence
	                insert_name=$(awk -v insert=${insert} '$2==insert' ${dir}/${stop}.out | cut -f 1) #define each insert's name
        	        echo -e "${insert_name}\t${new_start}" >> ${dir}/${stop}.int #print the insert name and starting position to a temp file
            	done
            	for term in ${insert_positions_stop[@]}; do #for each ending position
                	new_end=$((${term}+${real_start})) #define the ending position based on the position of the whole nested element within the artificial sequence
                	repeat_name=$(awk -v term=${term} '$3==term' ${dir}/${stop}.out | cut -f 1) #define each insert's name
	                echo -e "${repeat_name}\t${new_end}" >> ${dir}/${stop}.int2  #print the insert name and ending position to a temp file
	    	done

#print the insert names from the out file, #print the starting position numbers, #print the ending position numbers, #print the strand types, + or -, #print the extra1 information, *note no extra 2 for these, could see about adding later, & #print the repeat names
		paste -d '\t' <(cut -f 1 ${dir}/${stop}.out) \
		<(cut -f 2 ${dir}/${stop}.int) \
		<(cut -f 2 ${dir}/${stop}.int2) \
		<(cut -f 1 ${dir}/${stop}.out | cut -d: -f 3) \
		<(cut -f 1 ${dir}/${stop}.out | cut -d: -f 4-8) \
		<(cut -f 1 ${dir}/${stop}.out | cut -d: -f 1,2) \
		> ${dir}/${stop}.int3 #pastes the insert name and its start/end positions in the artificial sequence
		awk -v num="${num}" -v model="${model}" -f /datacommons/yoderlab/programs/Garlic-1.4/Garlic-1.4/log/scripts/nested_gff.awk ${dir}/${stop}.int3 \
		> ${dir}/${stop}.final #final file before adding together gff files, runs the int3 file through an awk script that mirrors the gff file columns like the single TEs above

#		count_3=$((cat ${dir}/${stop}.final | wc -l)+1) #count the number of nested TEs and add one to reflect the full nested TE
		cat ${dir}/${stop}.final >> /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_nest.gff #put file contents into new gff

		#Print the full-length nested TE as a gff file line
		start_2=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 1 | sed 's/.* //')
		actual_start=$((${start_2}+1))
        	stop_ini=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 2)
	        strand_2=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | cut -d: -f 3)
        	repeat_2=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | cut -d: -f 1,2)
	        extra1_2=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 4 | cut -d: -f 4-8)
        	extra2_2=$(awk -v stop=${stop} '$2==stop' ${final_nest_file} | cut -f 5 | cut -d ' ' -f 1-16 | tr -d ' ')
	        echo -e "${model}_artificial_sequence_${num}\tGARLIC\t${repeat_2}\t${actual_start}\t${stop_2}\t100\t${strand_2}\t.\t${extra1_2};${extra2_2}" \
                >> /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_nest.gff


	done
	count_4=$(cat /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_nest.gff | wc -l) #count the full file length after adding in nested TEs
	#cat /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}.gff /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_nest.gff > /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_final.gff
	#count_5=$(cat /datacommons/yoderlab/users/hkania/garlic_gffs/${model}/${model}_artificial_sequence_${num}_final.gff)
	#addition=$(${count_4}+${length}) #add the total of the nested TEs and the length of the single TE GFF file
	echo "Finished nested_TE GFF recording for Sequence ${model}_artificial_sequence_${num}"
	echo "nested_TE_total GFF length = ${count_4}"
	#echo "Counts: final GFF file = ${count_5}, nested_TE_total = ${count_4}, single_TE_total = ${length}"
	#echo "Final GFF count should equal ${addition}"
	date
	echo "Gzipping Alignment Files"
	date

	mkdir -p /cwork/hpk4/insert_splitting/${model}/${num}/alignments #make an alignment directory
	align_dir=/cwork/hpk4/insert_splitting/${model}/${num}/alignments #define the directory
	mkdir -p /cwork/hpk4/insert_splitting/${model}/${num}/final
	final_dir=/cwork/hpk4/insert_splitting/${model}/${num}/final
	mkdir -p /cwork/hpk4/insert_splitting/${model}/${num}/int
	int_dir=/cwork/hpk4/insert_splitting/${model}/${num}/int
	mv /cwork/hpk4/insert_splitting/${model}/${num}/*align ${align_dir} #move the alignment files to the alignment directory
	mv /cwork/hpk4/insert_splitting/${model}/${num}/*int* ${int_dir} #move intermediate files to alignment directory
	mv /cwork/hpk4/insert_splitting/${model}/${num}/*out ${int_dir} #move the temporary output files to the alignment directory
	mv /cwork/hpk4/insert_splitting/${model}/${num}/*final ${final_dir} #move the final files to the final directory
	gzip_dir_2=${model}_${num}_ncbi.tar.gz #gzip the directory to compress and save space
	tar -zcvf ${gzip_dir_2} ${align_dir} ${final_dir} ${int_dir}

#	rm -r ${align_dir} #remove the alignment directory
#	rm -r ${final_dir} #remove the final directory
	echo "Alignment Files can be found in ${gzip_dir_2}"
	date

done
echo "Finished Nested TE GFF Generation for all specified sequences"
echo "Model ${model}, first artifical sequence: ${END}, last artificial sequence: ${LAST}"
echo "DID NOT REMOVE INTERMEDIATE DIRECTORIES, DO THAT IF WORKED"
date


echo "###Finished Section 3"
echo "#############################"
date
echo "#############################"
echo -e "\n## Done with script."
