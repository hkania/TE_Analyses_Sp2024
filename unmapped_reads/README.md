# Unmapped_Reads

Below are descriptions of the sub-directories within the unmapped_reads directory.

## TE_blast
### metadata
* The metadata directory within TE_blast incudes two text files. The first is a text file with 10 assembly paths used for a first pass trial. Once that trial was confirmed, the workflow was performed on all samples. The second is a text file with the full assembly paths for all samples (excluding the 10 used as a first trial pass).
* These paths are referenced by ncbi_blast.sh in the scripts directory. They allow for an array of jobs to be scheduled to run blast on x number of files all at once.

### scripts
* The scripts directory within TE_blast includes on bash script. It calls upon a .txt file in the metadata folder to run an array of jobs across the specified assembly files.
* If re-running the script on new assemblies, one needs to change:
  * the path to the metadata folder in the alignment variable
  * the array values in SBATCH to mirror the correct numbe of samples
  * conda environment (unless you are Hannah, you need to make a conda environment with ncbi_blast + installed)
* Make sure the path to repbase_ncbi is specified in relation to the directory in which the sbatch command is called. Here, it was called in TE_blast.

### repbase_ncbi
* repbase database configured for NCBI blast following the workflow for "Making Repbase database for NCBI_blast+" in the wiki linked [here](https://github.com/hkania/TE_Analyses_Sp2024/wiki/Workflows#making-repbase-database-for-ncbi_blast).
* One file is not included, as it is quite large:
  * repbase_ncbi.nsq ~65MB

## abyss_unmapped
### P1
* Files generated when running the abyss assembler on petricky1 sample to compare abyss outputs to Megahit outputs.

### fasta
* fast and bam files for AM10 sample for trials using the abyss assembler.
* The fasta files are representative of unmapped reads from samples when pulled from mapped reads using samtools.
  
### log
* outputs and error files from abyss assembly trials

### scripts
* Three scripts from trials with the abyss assembler
  * abyss_test : run on the AM10 samples, used the online [abyss github](https://github.com/bcgsc/abyss) for parameters.
  * abyss_test_P1 : run on the petricky1 sample to compare abyss outputs to Megahit outputs (seems megahit gives much longer output contigs).
  * abyss_test_nokc : specified nokc value to compare outputs to abyss_test.sh when those are specified (did not seem to have much of an effect).
 
## megahit
### metadata
* good_paths_Tsim.txt : file generated by reads.awk script from names_Tsim.txt
* good_paths_all.txt : file generated by reads.awk script from names_all_excl_Tsim.txt
* names_Tsim.txt : names of the samples up to _R1 and _R2 for 10 trial samples
* names_all_excl_Tsim.txt : names of the samples up to _R1 and _R2 for remaining samples; .awk script uses this file so need to change in combination with that script if running in the future
* read_paths.txt : full read paths for all unmapped .R1 samples from the first sequencing run in 2023

### scripts
* megahit_P1 : bash scripts associated with P1 trial on megahit versus abyss assemblies. _SE script is when trimmomatic is run first and then paired and unpaired reads are specified.
* megahit_array.sh : bash script for running megahit on an array; necessary files and changes for when running on new samples are descriped in the script
* reads.awk : awk script for generating a file with the correct paths for all samples that are generated from running trimmomatic array script;
  * will need to run as `awk -f reads.awk file_of_interst_with_sample_names.txt > good_paths_output_file.txt`
  * will need to edit the print commands to reflect the correct paths
* trimmomatic_array.sh : trimmomatic script for running over an array of samples; requires a names.txt for grep to find samples and paths.txt file for specifying outputs

## example_data/P1_S17_SE_assembly
* folder containing example data and output for one sample (P1 - Petricky 1)
* checkpoints.txt, done, log, options,json : files generated from megahit
  * to see the statistics for the megahit assembly, run `tail -n 2 log'
* final.contigs.fa : **Most important file, final contigs that are then blasted agains repbase**
* patricky1_blastn.txt : tabular formatted output file after blasting final.contigs.fa against the repbase database
  
### intermediate_contigs
* intermediate contig files generated by de Brujin graphs from Megahit

## historical_hybrids_metadata.csv file
* Metadata about the samples included in the 2023 sequencing run and thrown into the unmapped_reads pipelines.
